# Davis Unified Intelligence System Configuration
# A-LMI v2.0

# Event Bus (Kafka)
event_bus:
  bootstrap_servers: ["localhost:9092"]
  topics:
    raw_web_content: "raw.web.content"
    raw_audio_transcript: "raw.audio.transcript"
    raw_audio_environment: "raw.audio.environment"
    processed_lighttokens: "processed.lighttokens"
    ai_commands: "ai.commands"
    simulation_state: "simulation.state"

# Memory Tiers
memory:
  # Tier 1: Raw Data Lake (MinIO)
  tier1:
    endpoint: "localhost:9000"
    access_key: "minioadmin"
    secret_key: "minioadmin"
    bucket: "raw-data-archive"
    secure: false
    
  # Tier 2: Vector Database (Milvus)
  tier2:
    host: "localhost"
    port: 19530
    collections:
      semantic_embeddings:
        dimension: 1536
        metric_type: "IP"  # Inner Product (cosine similarity)
        index_type: "HNSW"
      spectral_signatures:
        dimension: 1536
        metric_type: "L2"
        index_type: "HNSW"
        
  # Tier 3: Temporal Knowledge Graph (Neo4j)
  tier3:
    uri: "bolt://localhost:7687"
    user: "neo4j"
    password: "neo4j_password"
    database: "a_lmi_kg"

# Services
services:
  # Global Crawler
  crawler:
    robots_txt_respect: true
    max_concurrent_requests: 16
    download_delay: 0.5
    user_agent: "A-LMI-Bot/2.0"
    
  # Audio Processing
  audio_processor:
    vosk_model_path: "D:/CST/model/vosk-model-small-en-us-0.15"
    sample_rate: 16000
    chunk_size: 4096
    esc_model_type: "yamnet"  # or custom CNN/Transformer
    
  # Processing Core
  processing_core:
    clip_model: "openai/clip-vit-base-patch32"
    embedding_dimension: 1536
    perceptual_hash_algorithm: "pHash"  # or "SimHash"
    
  # Reasoning Engine
  reasoning_engine:
    math_model: "openai/o1-mini"
    hypothesis_generation_interval: 300  # seconds
    max_experiment_duration: 3600  # seconds

# Unity VLCL Simulation
vlcl:
  unity_executable: "vlcl_simulation/vlcl_simulation.exe"
  ipc_port: 5555  # ZeroMQ port
  physics:
    alpha: 1.0    # Harmonic bowl scale
    beta: 0.5     # Gravity scale
    gamma: 0.3    # Connectivity scale
    phi: 1.618    # Golden Ratio
    damping_zeta: 0.1
    swirl_gain: 0.05
    noise_amplitude: 0.01

# Security
security:
  encryption_algorithm: "AES-256"
  kms_provider: "hashicorp_vault"
  vault_addr: "http://localhost:8200"
  vault_token: ""  # Set via environment variable
  
# Interface
interface:
  conversational:
    framework: "gradio"  # or "streamlit"
    port: 7860
    theme: "dark"
    tts:
      enabled: true
      prosody_matching: true
      voice: "default"
      
  visualization:
    library: "plotly"  # or "viser"
    width: 1200
    height: 800
    animated: true

# Paths
paths:
  ai_data: "ai/data"
  ai_data_dictionaries: "ai/data/dictionaries"
  ai_models: "ai/models"
  ai_models_finetune: "ai/models/fine_tune_llm"
  
# Logging
logging:
  level: "INFO"
  file: "logs/a_lmi.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5
  
# GPU
gpu:
  enabled: true
  device: "cuda:0"
  
# Performance
performance:
  batch_size: 32
  num_workers: 4
  prefetch_factor: 2

